This paper proves monotony property of Neural networks that model a physical system (breaks in an airplane), where monotony is a physical property of the approximated model that we want the NN to have.

> Today, state-of-the-art methods for enforcing partial monotony
No citation here, what are they refering to? De Maria et al?

They propose a refinement of the monotony property: it has to be monotonous only in the desired area -> moving the burden of verification from the verifier to the specification

Related works discussion: Some methods merely encourage monotony without enforcing it.
Some methods enforce it for continuous variables
Others use hand-designed structures that enforce monotony but make training harder
Urban, C., Christakis, M., W Ìˆ ustholz, V., Zhang, F.: Perfectly parallel fairness certification of neural networks, considers monotony for discrete input spaces

The goal is not to prove monotonicity glabally but identify regions for which monotonicity holds and those which don't.
Could this be translated to a structural property, i.e. quantified on networks?

Meeting

SMT-coq solver by Chantal Keller describes connecting an SMT solver to Coq
Isabelle proof assistant based on HOL - Sledgehammer tool
#1 To ask Grant - how does Imandra exposes its proofs? High-level vs. low-level, type-theory based

Proof transport: ex. Dedukti

Ask Matthew what should be the output of the Certifier

Find a concrete verification example to get started from:
- Vehicle paper, car problem
- Coq implementation

Start reading list for papers to read in more details (add bullet points of why it is on my reading list)
